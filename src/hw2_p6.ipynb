{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7949c03b",
   "metadata": {},
   "source": [
    "Change '../data/' to your local directory where the two folders 'easy_ham' and 'spam' are saved. Import all required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "548610f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, classification_report, confusion_matrix\n",
    "\n",
    "dir_data = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd46f31",
   "metadata": {},
   "source": [
    "Read email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c984d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_email(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        msg = email.message_from_bytes(f.read())\n",
    "    # Get email headers\n",
    "    subject = msg.get('Subject')\n",
    "\n",
    "    # Read email's body\n",
    "    body = str(msg.get_payload())\n",
    "\n",
    "    # Remove HTML tags\n",
    "    body = BeautifulSoup(body).get_text()\n",
    "    \n",
    "    return subject, body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403231ea",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97790ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = str(text) # make sure input type is string.\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    text = text.lower() # Make lower case.\n",
    "    text = re.sub(r'=\\n', '', text)  # Remove =\\n.\n",
    "    text = re.sub(r'\\n', ' ', text)  # Remove \\n.\n",
    "    text = ' '.join(text.split())  # Replace all whitespaces to one space.\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    processed_tokens = []\n",
    "    for token in doc:\n",
    "        if token.like_url: # Check for URLs.\n",
    "            processed_tokens.append(\"urllink\") # Replace actual URL link to a word 'urllink'\n",
    "            continue\n",
    "        if token.like_email: # Check for email addresses.\n",
    "            processed_tokens.append(\"emailaddress\") # Replace actual email address to a word 'emailaddress'\n",
    "            continue\n",
    "        if not token.is_stop and not token.is_punct: # Check for stopwords and punctuations.\n",
    "            processed_tokens.append(token.lemma_) # Lemmatization.\n",
    "    text = \" \".join(processed_tokens)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) # Leave only alphabets and whitespaces.\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b5e472",
   "metadata": {},
   "source": [
    "Pathlib to read files in data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c18ad3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "dir_spam = Path(dir_data+\"spam\")\n",
    "dir_ham = Path(dir_data+\"easy_ham\")\n",
    "\n",
    "files_spam = list(dir_spam.iterdir())\n",
    "files_ham = list(dir_ham.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefe96c6",
   "metadata": {},
   "source": [
    "Test above functions on the first ham mail using TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c815c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Preprocessed body:\n",
      "    url urllink date supply blake blogs mpt want mozilla look like msie admit evidence pretty compelling recall ask agree mpt  list quote list agree item mpt mention problem course people problem mind mpt agree problem necessarily agree solution problem maybe different idea solve particular issue believe issue need address cover list specifically navigator chrome structure necessarily agree mpt propose default configuration agree chrome structure painfully restrictive customizable toolbar need implement order acquire flexibility deal problem speed argue cut lot useless ui feature chrome help substantially reduce bloat gain speed text editing use chimera mac textfield widget easily painful entire application buggy slow misbehave edit way expect imo chimera usability problem message display yes argument search yeah mess know mess menu structure get blog app separate menu structure complicate order deal multiple application clean separation naturally simplify menu eg eliminate new submenu easily migration problem imo face mozilla context menus mpt complain click context menu os default win overwhelmingly bring context menu mouse like complain win cite mozilla usability problem follow convention operating system simply listen wmcontextmenu message message fire win want fire validation err usability problem average bear completely irrelevant preference imo high list preference tangled pathetic mess separate pref individual app unique dialog simplify thing great deal remove nearly half preference exist gui mozilla ridiculously overconfigurable  urllink  urllink\n",
      "*Feature names for TF-IDF:\n",
      " ['acquire' 'address' 'admit' 'agree' 'app' 'application' 'argue'\n",
      " 'argument' 'ask' 'average' 'bear' 'believe' 'blake' 'bloat' 'blog'\n",
      " 'blogs' 'bring' 'buggy' 'chimera' 'chrome' 'cite' 'clean' 'click'\n",
      " 'compelling' 'complain' 'completely' 'complicate' 'configuration'\n",
      " 'context' 'convention' 'course' 'cover' 'customizable' 'cut' 'date'\n",
      " 'deal' 'default' 'dialog' 'different' 'display' 'easily' 'edit' 'editing'\n",
      " 'eliminate' 'entire' 'err' 'evidence' 'exist' 'expect' 'face' 'feature'\n",
      " 'flexibility' 'follow' 'gain' 'great' 'gui' 'half' 'help' 'high' 'idea'\n",
      " 'imo' 'implement' 'individual' 'irrelevant' 'issue' 'item' 'know' 'like'\n",
      " 'list' 'listen' 'look' 'lot' 'mac' 'maybe' 'mention' 'menu' 'menus'\n",
      " 'mess' 'message' 'migration' 'mind' 'misbehave' 'mouse' 'mozilla' 'mpt'\n",
      " 'msie' 'multiple' 'naturally' 'navigator' 'nearly' 'necessarily' 'need'\n",
      " 'new' 'operating' 'order' 'os' 'overconfigurable' 'overwhelmingly'\n",
      " 'painful' 'painfully' 'particular' 'pathetic' 'people' 'pref'\n",
      " 'preference' 'pretty' 'problem' 'propose' 'quote' 'recall' 'reduce'\n",
      " 'remove' 'restrictive' 'ridiculously' 'search' 'separate' 'separation'\n",
      " 'simplify' 'simply' 'slow' 'solution' 'solve' 'specifically' 'speed'\n",
      " 'structure' 'submenu' 'substantially' 'supply' 'tangled' 'text'\n",
      " 'textfield' 'thing' 'toolbar' 'ui' 'unique' 'url' 'urllink' 'usability'\n",
      " 'use' 'useless' 'validation' 'want' 'way' 'widget' 'win' 'wmcontextmenu'\n",
      " 'yeah' 'yes']\n",
      "*Shape of TF-IDF:\n",
      "      (1, 148)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Add an additional filter for stopwords from TF-IDF.\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "subject, body = parse_email(files_ham[0])\n",
    "body_preprocess = preprocess(body)\n",
    "body_tfidf = vectorizer.fit_transform([body_preprocess])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "# print(body)\n",
    "print(f\"*Preprocessed body:\\n    {body_preprocess}\")\n",
    "print(f\"*Feature names for TF-IDF:\\n {feature_names}\")\n",
    "print(f\"*Shape of TF-IDF:\\n      {body_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342fce3b",
   "metadata": {},
   "source": [
    "Create a dataframe with preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6966cd2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     subject_ham, body_ham \u001b[38;5;241m=\u001b[39m parse_email(file)\n\u001b[1;32m      7\u001b[0m     subject\u001b[38;5;241m.\u001b[39mappend(preprocess(subject_ham))\n\u001b[0;32m----> 8\u001b[0m     body\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody_ham\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m     label\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files_spam:\n",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpreprocess\u001b[39m(text):\n\u001b[1;32m      2\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(text) \u001b[38;5;66;03m# make sure input type is string.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;66;03m# Make lower case.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, text)  \u001b[38;5;66;03m# Remove =\\n.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds5220/lib/python3.9/site-packages/spacy/__init__.py:52\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     29\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     36\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds5220/lib/python3.9/site-packages/spacy/util.py:477\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_lang_class(name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblank:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))()\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_package(name):  \u001b[38;5;66;03m# installed as package\u001b[39;00m\n\u001b[0;32m--> 477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(name)\u001b[38;5;241m.\u001b[39mexists():  \u001b[38;5;66;03m# path to model data directory\u001b[39;00m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds5220/lib/python3.9/site-packages/spacy/util.py:513\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \n\u001b[1;32m    498\u001b[0m \u001b[38;5;124;03mname (str): The package name.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(name)\n\u001b[0;32m--> 513\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds5220/lib/python3.9/site-packages/en_core_web_sm/__init__.py:10\u001b[0m, in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moverrides):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_init_py\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds5220/lib/python3.9/site-packages/spacy/util.py:694\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE052\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mdata_path))\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds5220/lib/python3.9/site-packages/spacy/util.py:559\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    550\u001b[0m config \u001b[38;5;241m=\u001b[39m load_config(config_path, overrides\u001b[38;5;241m=\u001b[39moverrides)\n\u001b[1;32m    551\u001b[0m nlp \u001b[38;5;241m=\u001b[39m load_model_from_config(\n\u001b[1;32m    552\u001b[0m     config,\n\u001b[1;32m    553\u001b[0m     vocab\u001b[38;5;241m=\u001b[39mvocab,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    557\u001b[0m     meta\u001b[38;5;241m=\u001b[39mmeta,\n\u001b[1;32m    558\u001b[0m )\n\u001b[0;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds5220/lib/python3.9/site-packages/spacy/language.py:2247\u001b[0m, in \u001b[0;36mLanguage.from_disk\u001b[0;34m(self, path, exclude, overrides)\u001b[0m\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude:  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m   2245\u001b[0m     \u001b[38;5;66;03m# Convert to list here in case exclude is (default) tuple\u001b[39;00m\n\u001b[1;32m   2246\u001b[0m     exclude \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(exclude) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m-> 2247\u001b[0m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeserializers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   2248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m path  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   2249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_link_components()\n",
      "File \u001b[0;32m~/miniconda3/envs/ds5220/lib/python3.9/site-packages/spacy/util.py:1401\u001b[0m, in \u001b[0;36mfrom_disk\u001b[0;34m(path, readers, exclude)\u001b[0m\n\u001b[1;32m   1398\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, reader \u001b[38;5;129;01min\u001b[39;00m readers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1399\u001b[0m     \u001b[38;5;66;03m# Split to support file names like meta.json\u001b[39;00m\n\u001b[1;32m   1400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude:\n\u001b[0;32m-> 1401\u001b[0m         \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "File \u001b[0;32m~/miniconda3/envs/ds5220/lib/python3.9/site-packages/spacy/language.py:2223\u001b[0m, in \u001b[0;36mLanguage.from_disk.<locals>.deserialize_vocab\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m   2221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeserialize_vocab\u001b[39m(path: Path) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m-> 2223\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds5220/lib/python3.9/site-packages/spacy/vocab.pyx:553\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab.from_disk\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds5220/lib/python3.9/site-packages/spacy/vectors.pyx:718\u001b[0m, in \u001b[0;36mspacy.vectors.Vectors.from_disk\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds5220/lib/python3.9/site-packages/spacy/util.py:1392\u001b[0m, in \u001b[0;36mfrom_disk\u001b[0;34m(path, readers, exclude)\u001b[0m\n\u001b[1;32m   1388\u001b[0m             writer(path \u001b[38;5;241m/\u001b[39m key)\n\u001b[1;32m   1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m path\n\u001b[0;32m-> 1392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_disk\u001b[39m(\n\u001b[1;32m   1393\u001b[0m     path: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m   1394\u001b[0m     readers: Dict[\u001b[38;5;28mstr\u001b[39m, Callable[[Path], \u001b[38;5;28;01mNone\u001b[39;00m]],\n\u001b[1;32m   1395\u001b[0m     exclude: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   1396\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Path:\n\u001b[1;32m   1397\u001b[0m     path \u001b[38;5;241m=\u001b[39m ensure_path(path)\n\u001b[1;32m   1398\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, reader \u001b[38;5;129;01min\u001b[39;00m readers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1399\u001b[0m         \u001b[38;5;66;03m# Split to support file names like meta.json\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "subject = []\n",
    "body = []\n",
    "label = []\n",
    "\n",
    "for file in files_ham:\n",
    "    subject_ham, body_ham = parse_email(file)\n",
    "    subject.append(preprocess(subject_ham))\n",
    "    body.append(preprocess(body_ham))\n",
    "    label.append(0)\n",
    "\n",
    "for file in files_spam:\n",
    "    subject_spam, body_spam = parse_email(file)\n",
    "    subject.append(preprocess(subject_spam))\n",
    "    body.append(preprocess(body_spam))\n",
    "    label.append(1)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'subject': subject,\n",
    "        'body': body,\n",
    "        \n",
    "        'target': label\n",
    "    }\n",
    ")\n",
    "df.to_csv(dir_data+'data_spam.csv', index=False) # Load csv file instead of running preprocessing again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7110de1b",
   "metadata": {},
   "source": [
    "Above cell requires about 24 minutes on preprocessing, so I recommend directly using the preprocessed csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f72b68a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usability problem mozilla</td>\n",
       "      <td>url urllink date supply blake blogs mpt want m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exmh speed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hanson sept  message national review</td>\n",
       "      <td>hanson good sci fi author plan slip follow lin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>use new apt null rh upgrade</td>\n",
       "      <td>matthias saou emailaddress write  red hat reco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>satalk funny</td>\n",
       "      <td>wednesday  august   cet theo van dinter write ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>low cost easy use conference</td>\n",
       "      <td>low rate service conference easy  cent minute ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>shape summer</td>\n",
       "      <td>see nbc cbs cnn oprah health discovery actuall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>american millionaire reveal secret source weal...</td>\n",
       "      <td>hello                                         ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>gain low interest rate  year</td>\n",
       "      <td>opportunity knock mortgage rate rise national ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>fw short term buy recommendation</td>\n",
       "      <td>otc newsletter discover tomorrow winner immedi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3001 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                subject  \\\n",
       "0                             usability problem mozilla   \n",
       "1                                            exmh speed   \n",
       "2                  hanson sept  message national review   \n",
       "3                           use new apt null rh upgrade   \n",
       "4                                          satalk funny   \n",
       "...                                                 ...   \n",
       "2996                       low cost easy use conference   \n",
       "2997                                       shape summer   \n",
       "2998  american millionaire reveal secret source weal...   \n",
       "2999                       gain low interest rate  year   \n",
       "3000                   fw short term buy recommendation   \n",
       "\n",
       "                                                   body  target  \n",
       "0     url urllink date supply blake blogs mpt want m...       0  \n",
       "1                                                   NaN       0  \n",
       "2     hanson good sci fi author plan slip follow lin...       0  \n",
       "3     matthias saou emailaddress write  red hat reco...       0  \n",
       "4     wednesday  august   cet theo van dinter write ...       0  \n",
       "...                                                 ...     ...  \n",
       "2996  low rate service conference easy  cent minute ...       1  \n",
       "2997  see nbc cbs cnn oprah health discovery actuall...       1  \n",
       "2998  hello                                         ...       1  \n",
       "2999  opportunity knock mortgage rate rise national ...       1  \n",
       "3000  otc newsletter discover tomorrow winner immedi...       1  \n",
       "\n",
       "[3001 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df  = pd.read_csv(dir_data+\"data_spam.csv\")\n",
    "df.head(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db77fd",
   "metadata": {},
   "source": [
    "Find NaN in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "033e751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts per spam columns:\n",
      "subject      5\n",
      "body       100\n",
      "target       0\n",
      "dtype: int64\n",
      "NaN counts per ham columns:\n",
      "subject    15\n",
      "body       92\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cnt_nan_spam = df[df['target']==1].isna().sum()\n",
    "cnt_nan_ham = df[df['target']==0].isna().sum()\n",
    "\n",
    "print(\"NaN counts per spam columns:\")\n",
    "print(cnt_nan_spam)\n",
    "print(\"NaN counts per ham columns:\")\n",
    "print(cnt_nan_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d60d306",
   "metadata": {},
   "source": [
    "Remove all rows with NaN. 3001 rows are reduced to 2793 rows. We lost 20% of spam data (~100 out of 500) and 4% of ham data (~100 out of 2500)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b91c80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df without NaN:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usability problem mozilla</td>\n",
       "      <td>url urllink date supply blake blogs mpt want m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hanson sept  message national review</td>\n",
       "      <td>hanson good sci fi author plan slip follow lin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>use new apt null rh upgrade</td>\n",
       "      <td>matthias saou emailaddress write  red hat reco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>satalk funny</td>\n",
       "      <td>wednesday  august   cet theo van dinter write ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>razor user use undefined value error</td>\n",
       "      <td>instal razor  freebsd  release box have proble...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>low cost easy use conference</td>\n",
       "      <td>low rate service conference easy  cent minute ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>shape summer</td>\n",
       "      <td>see nbc cbs cnn oprah health discovery actuall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>american millionaire reveal secret source weal...</td>\n",
       "      <td>hello                                         ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>gain low interest rate  year</td>\n",
       "      <td>opportunity knock mortgage rate rise national ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>fw short term buy recommendation</td>\n",
       "      <td>otc newsletter discover tomorrow winner immedi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2793 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                subject  \\\n",
       "0                             usability problem mozilla   \n",
       "2                  hanson sept  message national review   \n",
       "3                           use new apt null rh upgrade   \n",
       "4                                          satalk funny   \n",
       "5                  razor user use undefined value error   \n",
       "...                                                 ...   \n",
       "2996                       low cost easy use conference   \n",
       "2997                                       shape summer   \n",
       "2998  american millionaire reveal secret source weal...   \n",
       "2999                       gain low interest rate  year   \n",
       "3000                   fw short term buy recommendation   \n",
       "\n",
       "                                                   body  target  \n",
       "0     url urllink date supply blake blogs mpt want m...       0  \n",
       "2     hanson good sci fi author plan slip follow lin...       0  \n",
       "3     matthias saou emailaddress write  red hat reco...       0  \n",
       "4     wednesday  august   cet theo van dinter write ...       0  \n",
       "5     instal razor  freebsd  release box have proble...       0  \n",
       "...                                                 ...     ...  \n",
       "2996  low rate service conference easy  cent minute ...       1  \n",
       "2997  see nbc cbs cnn oprah health discovery actuall...       1  \n",
       "2998  hello                                         ...       1  \n",
       "2999  opportunity knock mortgage rate rise national ...       1  \n",
       "3000  otc newsletter discover tomorrow winner immedi...       1  \n",
       "\n",
       "[2793 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = df.dropna()\n",
    "print(\"df without NaN:\")\n",
    "df_cleaned.head(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213252f8",
   "metadata": {},
   "source": [
    "Create a function to train and test different models. TF-IDF and test-train split are applied within the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aa77e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, X, y, test_size=0.2, random_state=42, **kwargs):\n",
    "    model_map = {\n",
    "        'Logistic': LogisticRegression,\n",
    "        'KNN': KNeighborsClassifier,\n",
    "        'GaussianNB': GaussianNB,\n",
    "        'MultinomialNB': MultinomialNB,\n",
    "        'BernoulliNB': BernoulliNB,\n",
    "    }\n",
    "    model_class = model_map.get(model_name)\n",
    "    model = model_class(**kwargs) # Create chosen model with hyperparameters.\n",
    "\n",
    "    # Apply TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "    # Split test-train set.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    model.fit(X_train, y_train) # Train model.\n",
    "    y_pred = model.predict(X_test) # Predict y.\n",
    "\n",
    "    # Metric scores.\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, labels=[0, 1])\n",
    "    cmatrix = confusion_matrix(y_test, y_pred)\n",
    "    return recall, precision, report, cmatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09184b05",
   "metadata": {},
   "source": [
    "Testing models with X as body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7a3f4936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLogistic model:\u001b[0m\n",
      "Recall: 0.5894736842105263 / Precision: 1.0\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       464\n",
      "           1       1.00      0.59      0.74        95\n",
      "\n",
      "    accuracy                           0.93       559\n",
      "   macro avg       0.96      0.79      0.85       559\n",
      "weighted avg       0.94      0.93      0.92       559\n",
      "\n",
      "Confusion matrix:\n",
      "[[464   0]\n",
      " [ 39  56]]\n",
      "\n",
      "\u001b[1mKNN model:\u001b[0m\n",
      "Recall: 0.8736842105263158 / Precision: 0.9431818181818182\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       464\n",
      "           1       0.94      0.87      0.91        95\n",
      "\n",
      "    accuracy                           0.97       559\n",
      "   macro avg       0.96      0.93      0.94       559\n",
      "weighted avg       0.97      0.97      0.97       559\n",
      "\n",
      "Confusion matrix:\n",
      "[[459   5]\n",
      " [ 12  83]]\n",
      "\n",
      "\u001b[1mMultinomialNB model:\u001b[0m\n",
      "Recall: 0.11578947368421053 / Precision: 1.0\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       464\n",
      "           1       1.00      0.12      0.21        95\n",
      "\n",
      "    accuracy                           0.85       559\n",
      "   macro avg       0.92      0.56      0.56       559\n",
      "weighted avg       0.87      0.85      0.80       559\n",
      "\n",
      "Confusion matrix:\n",
      "[[464   0]\n",
      " [ 84  11]]\n",
      "\n",
      "\u001b[1mBernoulliNB model:\u001b[0m\n",
      "Recall: 0.29473684210526313 / Precision: 0.7368421052631579\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       464\n",
      "           1       0.74      0.29      0.42        95\n",
      "\n",
      "    accuracy                           0.86       559\n",
      "   macro avg       0.80      0.64      0.67       559\n",
      "weighted avg       0.85      0.86      0.84       559\n",
      "\n",
      "Confusion matrix:\n",
      "[[454  10]\n",
      " [ 67  28]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_to_test = ['Logistic', 'KNN', 'MultinomialNB', 'BernoulliNB']\n",
    "\n",
    "for model in models_to_test:\n",
    "    recall, precision, report, cmatrix = train_model(model, X=df_cleaned['body'], y=df_cleaned['target'])\n",
    "    print(f\"\\033[1m{model} model:\\033[0m\")\n",
    "    print(f\"Recall: {recall} / Precision: {precision}\")\n",
    "    print(f\"Classification report:\\n{report}\")\n",
    "    print(f\"Confusion matrix:\\n{cmatrix}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c754dbfe",
   "metadata": {},
   "source": [
    "Testing models with X as subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "646327c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic model:\n",
      "Recall: 0.15789473684210525 / Precision: 1.0\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       464\n",
      "           1       1.00      0.16      0.27        95\n",
      "\n",
      "    accuracy                           0.86       559\n",
      "   macro avg       0.93      0.58      0.60       559\n",
      "weighted avg       0.88      0.86      0.81       559\n",
      "\n",
      "Confusion matrix:\n",
      "[[464   0]\n",
      " [ 80  15]]\n",
      "KNN model:\n",
      "Recall: 0.5473684210526316 / Precision: 0.8125\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       464\n",
      "           1       0.81      0.55      0.65        95\n",
      "\n",
      "    accuracy                           0.90       559\n",
      "   macro avg       0.86      0.76      0.80       559\n",
      "weighted avg       0.90      0.90      0.89       559\n",
      "\n",
      "Confusion matrix:\n",
      "[[452  12]\n",
      " [ 43  52]]\n",
      "MultinomialNB model:\n",
      "Recall: 0.24210526315789474 / Precision: 1.0\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       464\n",
      "           1       1.00      0.24      0.39        95\n",
      "\n",
      "    accuracy                           0.87       559\n",
      "   macro avg       0.93      0.62      0.66       559\n",
      "weighted avg       0.89      0.87      0.84       559\n",
      "\n",
      "Confusion matrix:\n",
      "[[464   0]\n",
      " [ 72  23]]\n",
      "BernoulliNB model:\n",
      "Recall: 0.18947368421052632 / Precision: 0.72\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.92       464\n",
      "           1       0.72      0.19      0.30        95\n",
      "\n",
      "    accuracy                           0.85       559\n",
      "   macro avg       0.79      0.59      0.61       559\n",
      "weighted avg       0.83      0.85      0.81       559\n",
      "\n",
      "Confusion matrix:\n",
      "[[457   7]\n",
      " [ 77  18]]\n"
     ]
    }
   ],
   "source": [
    "models_to_test = ['Logistic', 'KNN', 'MultinomialNB', 'BernoulliNB']\n",
    "\n",
    "for model in models_to_test:\n",
    "    recall, precision, report, cmatrix = train_model(model, X=df_cleaned['subject'], y=df_cleaned['target'])\n",
    "    print(f\"{model} model:\")\n",
    "    print(f\"Recall: {recall} / Precision: {precision}\")\n",
    "    print(f\"Classification report:\\n{report}\")\n",
    "    print(f\"Confusion matrix:\\n{cmatrix}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds5220",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
